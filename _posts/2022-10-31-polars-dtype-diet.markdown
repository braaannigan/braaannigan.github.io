---
layout: post
title:  "Polars on a diet"
date:   2022-10-31 11:35:24 +0200
categories: software
---
# [Blog post index](/blog/blog_index.html)

# Polars on a diet
Published on: 31st October 2022

This post was created while writing my **Data Analysis with Polars course**. 
[*Check it out on Udemy*](https://www.udemy.com/course/data-analysis-with-polars/?referralCode=A29DCDA40D369080C05A)

Polars has a built in tool to go on a dtype diet.

Call the `shrink_dtype` expression and it will convert the column to the dtype that requires the least amount of memory based on the data in the column.

```python
import polars as pl

(
  pl.DataFrame(
  	{
    	"a": [1, 2, 3],
        "b": [1, 2, 2 << 32],
        "c": [-1, 2, 1 << 30],
        "d": [-112, 2, 112],
        "e": [-112, 2, 129],
        "f": ["a", "b", "c"],
        "g": [0.1, 1.32, 0.12],
        "h": [True, None, False],
     }
    )
  .select(
    pl.all().shrink_dtype()
  )
)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ a   â”† b          â”† c          â”† d    â”† e    â”† f   â”† g    â”† h     â”‚
â”‚ --- â”† ---        â”† ---        â”† ---  â”† ---  â”† --- â”† ---  â”† ---   â”‚
â”‚ i8  â”† i64        â”† i32        â”† i8   â”† i16  â”† str â”† f32  â”† bool  â”‚
â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
â”‚ 1   â”† 1          â”† -1         â”† -112 â”† -112 â”† a   â”† 0.1  â”† true  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 2   â”† 2          â”† 2          â”† 2    â”† 2    â”† b   â”† 1.32 â”† null  â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 3   â”† 8589934592 â”† 1073741824 â”† 112  â”† 129  â”† c   â”† 0.12 â”† false â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```
Both floats and integers default to 64-bit precision. In the example below from the API docs Polars sees that column "a" could be 8-bit, column "b" must be 64-bit, but column "c" could be 32-bit.

Casting numeric columns from 64-bit to 32-bit is often the easiest win in data science. Memory usage halves and computation time might also be half that of 64-bit.

You do need to check that the loss of precision is ok. I had sensors accurate to 0.01 so a change of 10^-6 was ðŸ‘

In my udemy course I show that if you cast to 8- or 16-bits memory usage continues to fall proportionally...

...but computation time probably won't be better than 32-bits!

Most modern CPUs don't have native support for 8- or 16-bit so they have to emulate it.

String columns with lots of repeated entries can also usefully be cast to categoricals. But that's a story for another day.

# Learn more
Want to know more about Polars for high performance data science and ML? Then you can:
- [join my Polars course on Udemy](https://www.udemy.com/course/data-analysis-with-polars/?referralCode=A29DCDA40D369080C05A) 
- [follow me on twitter](https://twitter.com/braaannigan)
- [connect with me at linkedin](https://www.linkedin.com/in/liam-brannigan-9080b214a/)
- [check out my youtube videos](https://www.youtube.com/watch?v=nGritAo-71o)

or **let me know if you would like a Polars workshop for your organisation**.